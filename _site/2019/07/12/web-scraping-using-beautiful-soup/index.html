<!DOCTYPE html><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><title>Web-scraping a Wikipedia article using Beautiful Soup - Table | SWC - Data Science</title><meta name="author" content="Sangwook Cheon"><meta name="description" content="N(one)-Stop Data Science"><meta property="og:title" content="Web-scraping a Wikipedia article using Beautiful Soup - Table | SWC - Data Science"><meta property="og:url" content="http://localhost:4000/2019/07/12/web-scraping-using-beautiful-soup/"><meta property="og:site_name" content="SWC - Data Science"><meta property="og:description" content="How to scrape Wikipedia page using Beautiful Soup library in Python."><meta property="og:image" content="/images/roman-romashov-GRxTDmbsJRM-unsplash (1).jpg"><meta property="og:type" content="blog"><meta name="twitter:card" content="summary"><meta name="twitter:description" content="How to scrape Wikipedia page using Beautiful Soup library in Python."><meta name="twitter:title" content="Web-scraping a Wikipedia article using Beautiful Soup - Table | SWC - Data Science"><meta name="twitter:url" content="http://localhost:4000/2019/07/12/web-scraping-using-beautiful-soup/"><meta name="twitter:site" content="SWC - Data Science"><meta name="twitter:creator" content="@"><meta name="twitter:domain" content="http://localhost:4000"><meta property="twitter:image" content="/images/roman-romashov-GRxTDmbsJRM-unsplash (1).jpg"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inconsolata|Lora|Space+Mono:700"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" href="/assets/css/main.css"><link rel="alternate" type="application/rss+xml" title="SWC - Data Science" href="http://localhost:4000/feed.xml"><link rel="canonical" href="http://localhost:4000/2019/07/12/web-scraping-using-beautiful-soup/"></head><main><style media="screen"> #particles-js { background-image: url('/images/roman-romashov-GRxTDmbsJRM-unsplash (1).jpg'); background-color: $color-black; background-repeat: no-repeat; background-size: cover; background-position: 50%; animation: fade-in 3s both; position: absolute; top: 0; left: 0; height: 100%; width: 100%; background-size: cover; background-repeat: no-repeat; /* background-position: 50%; */ @media not all and (hover:hover) { height: var(--app-height); } @media (min-width: 30em) { height: 35em; } &:after { @extend %overlay; } &__img { animation: fade-in 2s both; } &__container { display: flex; flex-direction: column; justify-content: flex-end; height: 100%; width: 90%; margin: 0 auto; } } p { font-size: 1.114em; margin-bottom: 1.3em; } ol, ul { margin: 1em; padding: 0; font-size: 1.114em; } .centered { position: absolute; top: 17.5em; left: 5%; width: 80%; justify-content: flex-end; margin: 0 auto; flex-direction: column; /* transform: translate(-50%, -50%); */ } .bottom-left { position: absolute; top: 40%; left: 10%; } html { scroll-behavior: smooth; } mark { background-color: $color-alpha; color: $color-black; padding: 2px; border-radius: 5px; }</style><article itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting"><header class="mast rellax" data-rellax-speed="-4"> <a class="nav nav--white" href="/"> <i class="fa fa-lg fa-arrow-left"></i> <span>Back to Posts</span> </a><div id='particles-js'></div><div class="mast__container"> <span style="color:#ffffff"><time datetime="2019-07-12T00:00:00+07:00" itemprop="datePublished">Jul 12, 2019</time></span><h1 style="font-family: $font-header;color:#ffffff" itemprop="name headline">Web-scraping a Wikipedia article using Beautiful Soup - Table</h1><h2 style="font-family: $font-header; color:#F59835" itemprop="name headline">By Sangwook Cheon</h2><span style="color:#ffffff; font-size:1.114em;">Posted in <a class="nav--white" href="/category/learn-ds"><mark>Learn-DS</mark></a>, <a class="nav--white" href="/category/obtaining-data"><mark>Obtaining-Data</mark></a> </span> <span></span> <br></div></header><section class="section-padding bg-grey" itemprop="articleBody"><div class="post"><h1 id="about-beautiful-soup">About Beautiful Soup</h1><p>Oftentimes, data we are looking for isn’t stored in the best format possible. While in some cases data is already prepared for us, such as dataset on Kaggle, sometimes we need to scrape the data out of a certain source. In my case, I had to get a table out of this <a href="https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M">Wikipedia article</a> containing all the neighborhoods in Canada.</p><p>I’ve recently found that a Python library called Beautiful Soup allows me to efficiently carry out this task.</p><p>According to <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">Beautiful Soup</a>,</p><blockquote><p>Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work.</p></blockquote><p>As of now, it is important to know that this library enables us to automatically scrape or get web content that is cleanable out of any website.</p><p><img src="/in-post-images/Screen Shot 2019-07-12 at 21.43.13.png" alt="" /> <em>This is the wikipedia article. I need to get the table out of this webpage so that it can be analyzed using Python.</em></p><div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;table</span> <span class="na">class=</span><span class="s">"wikitable sortable jquery-tablesorter"</span><span class="nt">&gt;</span>
<span class="nt">&lt;thead&gt;&lt;tr&gt;</span>
<span class="nt">&lt;th</span> <span class="na">class=</span><span class="s">"headerSort"</span> <span class="na">tabindex=</span><span class="s">"0"</span> <span class="na">role=</span><span class="s">"columnheader button"</span> <span class="na">title=</span><span class="s">"Sort ascending"</span><span class="nt">&gt;</span>Postcode<span class="nt">&lt;/th&gt;</span>
<span class="nt">&lt;th</span> <span class="na">class=</span><span class="s">"headerSort"</span> <span class="na">tabindex=</span><span class="s">"0"</span> <span class="na">role=</span><span class="s">"columnheader button"</span> <span class="na">title=</span><span class="s">"Sort ascending"</span><span class="nt">&gt;</span>Borough<span class="nt">&lt;/th&gt;</span>
<span class="nt">&lt;th</span> <span class="na">class=</span><span class="s">"headerSort"</span> <span class="na">tabindex=</span><span class="s">"0"</span> <span class="na">role=</span><span class="s">"columnheader button"</span> <span class="na">title=</span><span class="s">"Sort ascending"</span><span class="nt">&gt;</span>Neighbourhood
<span class="nt">&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;</span>
<span class="nt">&lt;tr&gt;</span>
<span class="nt">&lt;td&gt;</span>M1A<span class="nt">&lt;/td&gt;</span>
<span class="nt">&lt;td&gt;</span>Not assigned<span class="nt">&lt;/td&gt;</span>
<span class="nt">&lt;td&gt;</span>Not assigned
<span class="nt">&lt;/td&gt;&lt;/tr&gt;</span>
<span class="nt">&lt;tr&gt;</span>
<span class="nt">&lt;td&gt;</span>M2A<span class="nt">&lt;/td&gt;</span>
<span class="nt">&lt;td&gt;</span>Not assigned<span class="nt">&lt;/td&gt;</span>
<span class="nt">&lt;td&gt;</span>Not assigned
<span class="nt">&lt;/td&gt;&lt;/tr&gt;</span>
<span class="nt">&lt;tr&gt;</span>
<span class="nt">&lt;td&gt;</span>M3A<span class="nt">&lt;/td&gt;</span>
<span class="nt">&lt;td&gt;&lt;a</span> <span class="na">href=</span><span class="s">"/wiki/North_York"</span> <span class="na">title=</span><span class="s">"North York"</span><span class="nt">&gt;</span>North York<span class="nt">&lt;/a&gt;&lt;/td&gt;</span>
<span class="nt">&lt;td&gt;&lt;a</span> <span class="na">href=</span><span class="s">"/wiki/Parkwoods"</span> <span class="na">title=</span><span class="s">"Parkwoods"</span><span class="nt">&gt;</span>Parkwoods<span class="nt">&lt;/a&gt;</span>
<span class="nt">&lt;/td&gt;&lt;/tr&gt;</span>
<span class="nt">&lt;tr&gt;</span>
...
</code></pre></div></div><p>In HTML, the table looks like the above. <code class="highlighter-rouge">&lt;tr&gt;</code> is a unique row in the table, and each <code class="highlighter-rouge">&lt;td&gt;</code> is a table value.</p><p>Using Beautiful Soup, we will convert this HTML code into a Pandas DataFrame, which then can be clean and analyzed using Python.</p><h1 id="import-libraries">Import Libraries</h1><p>First we import important libraries including Beautiful Soup, and other tools that go hand-in-hand.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
</code></pre></div></div><p>Note: bs4 might need to be installed. ‘Requests’ library gets HTML file from the webpage.</p><h1 id="loading-html-and-finding-the-table-section">Loading HTML and finding the table section</h1><p>Now load the HTML file from a Wikipedia page containing information about postal codes of Canada. This will be processed using Beautiful Soup.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#.text to get pure HTML file.</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="s">'lxml'</span><span class="p">)</span>

<span class="c"># To quickly see the html</span>
<span class="k">print</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">prettify</span><span class="p">())</span>
</code></pre></div></div><p><code class="highlighter-rouge">.prettify</code> puts indents on HTML file so that is is more readable.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># From HTML, find a portion pertaining to the table.</span>
<span class="c">#_class is used to find a unique class name of the table, to make sure we find the correct table if there are multiple tables.</span>
<span class="n">raw_table</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'table'</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s">'wikitable sortable'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">raw_table</span><span class="o">.</span><span class="n">prettify</span><span class="p">())</span>
</code></pre></div></div><h1 id="processing">Processing</h1><p>Now let’s process the HTML of the table to convert it into a DataFrame. There are many rows with unassigned borough, and we need to ignore them as they have missing information that cannot be filled. A row is missing ‘Neighborhood’, then we should set it to be the same as borough.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#Get all rows from the table. &lt;tr&gt; tag refers to a row.</span>
<span class="n">rows_all</span> <span class="o">=</span> <span class="n">raw_table</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'tr'</span><span class="p">)</span>

<span class="c">#Initialize empty list.</span>
<span class="n">row_data</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c">#For each row, find table values and append it to the list.</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rows_all</span><span class="p">:</span>
    <span class="n">td</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'td'</span><span class="p">)</span>

    <span class="c">#A list of table values in one row</span>
    <span class="n">row</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">td</span><span class="p">]</span>

    <span class="c">#Only add cells with borough, and with three values</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">row</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="s">'Not assigned'</span><span class="p">:</span>
        <span class="n">row</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span> <span class="c">#to remove /n</span>
        <span class="c">#If Neighborhood is not assigned, the name is same as borough</span>
        <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="s">'Not assigned'</span><span class="p">:</span>
            <span class="n">row</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
          <span class="c">#Append the row to the big list.</span>
        <span class="n">row_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
</code></pre></div></div><p>Below is how to convert the list to a Pandas DataFrame:</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">row_data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'PostalCode'</span><span class="p">,</span> <span class="s">'Borough'</span><span class="p">,</span> <span class="s">'Neighborhood'</span><span class="p">])</span>

<span class="c">#preview ten rows of DataFrame</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div><p><img src="/in-post-images/Screen Shot 2019-07-12 at 22.09.12.png" alt="" /></p><p>The table is correctly loaded! We need to do one more step, which is to combine neighborhoods with same Postal Code into one row. So some of the postal codes will have multiple neighborhoods listed and separated by a comma.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">postal_codes</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">PostalCode</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">postal_codes</span><span class="p">)</span>
</code></pre></div></div><p><img src="/in-post-images/Screen Shot 2019-07-12 at 22.12.19.png" alt="" /> These are the unique Postal Codes.</p><div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#Set a new empty table with just column names.</span>
<span class="n">clean_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'PostalCode'</span><span class="p">,</span> <span class="s">'Borough'</span><span class="p">,</span> <span class="s">'Neighborhood'</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>

<span class="c">#Populate the new dataframe with unique postal codes.</span>
<span class="k">for</span> <span class="n">code</span> <span class="ow">in</span> <span class="n">postal_codes</span><span class="p">:</span>
    <span class="c"># Get DataFrame containing rows with same postal code.</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">'PostalCode'</span><span class="p">]</span> <span class="o">==</span> <span class="n">code</span><span class="p">]</span>
    <span class="n">borough</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="c"># Join each column into a string containing all neighborhoods in the same code.</span>
    <span class="n">df</span> <span class="o">=</span> <span class="s">', '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Neighborhood'</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>

    <span class="c">#Add to the new dataframe</span>
    <span class="n">clean_data</span> <span class="o">=</span> <span class="n">clean_data</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s">'PostalCode'</span><span class="p">:</span> <span class="n">code</span><span class="p">,</span> <span class="s">'Borough'</span><span class="p">:</span> <span class="n">borough</span> <span class="p">,</span> <span class="s">'Neighborhood'</span><span class="p">:</span> <span class="n">df</span><span class="p">},</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div><p><img src="/in-post-images/Screen Shot 2019-07-12 at 22.16.09.png" alt="" /> Now we can see that some postal codes now have a neighborhoods column with multiple names. The table is fully cleaned now, and ready to go. Sometimes it is useful to save this cleaned table as a csv to the local machine.</p><h1 id="recap">Recap</h1><p>In this post I explored some of the features of Beautiful Soup. It is often used together with Requests library to load HTML and find what we need from the HTML file. We can use <code class="highlighter-rouge">.find</code> and <code class="highlighter-rouge">find_all</code> to get textvalues out of HTML.</p><p>I will explore the library deeper in a future post. Thank you for reading!</p><div id="disqus_thread"></div><script> var disqus_config = function () { this.page.url = "http://localhost:4000/2019/07/12/web-scraping-using-beautiful-soup/"; this.page.identifier = "/2019/07/12/web-scraping-using-beautiful-soup"; }; (function() { var d = document, s = d.createElement('script'); s.src = 'https://sangwookcheon.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); </script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div></section><section class="profile"><div class="profile__card"><div class="profile__img"><figure class="absolute-bg" style="background-image: url('/images/SangwookCpic.png');"></figure></div><div class="profile__container"><p>My name is Sangwook Cheon, a high school student at Jakarta Intercultural School. After tinkering with various branches of technology, I discovered that I am most passionate about data. All kinds of data, from so well-known to absolutely obscure. I work with Python to extract and interact with numbers, texts, images, audio, and more to come soon.</p><ul class="profile__social"><li><a class="fa fa-lg fa-envelope-o" href="mailto:sangwookchn@gmail.com"></a></li><li><h3><a href="https://kaggle.com/sangwookchn">k</a></h3></li><li><a class="fa fa-lg fa-github" href="https://github.com/SangwookCheon" target="_blank"></a></li><li><a class="fa fa-lg fa-linkedin" href="https://www.linkedin.com/in/sangwookcheon/" target="_blank"></a></li><li><a class="fa fa-lg fa-medium" href="https://medium.com/@sangwookcheon" target="_blank"></a></li></ul></div></div></section></article><section class="next"> <a class="next__link" href="/2019/07/12/geopy-adding-latitude-longitude/" style="background-image: url('/images/nasa-_SFJhRPzJHs-unsplash (1).jpg');"><div class="next__container"> <span style="color:#ffffff;">Read Next</span><h3 style="color:#ffffff">Adding Latitude and Longitude given a location using Geocoder library</h3></div></a></section></main><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/rellax/1.0.0/rellax.min.js"></script> <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/wow/1.1.2/wow.min.js"></script> <script src="//cdn.jsdelivr.net/particles.js/2.0.0/particles.min.js"></script> <script> particlesJS.load('particles-js', "/assets/js/particles.json", function() { console.log('callback - particles.js config loaded'); }); </script> <script type="text/javascript" src="/assets/js/app.js"></script></body></html>
